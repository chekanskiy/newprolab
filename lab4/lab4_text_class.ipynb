{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def by_vect_cosine_similarity(v1, v2):\n",
    "    sumx2,  sumy2,  sumxy =  0, 0, 0\n",
    "    for x, y in zip(v1, v2):\n",
    "        sumx2 +=  x*x\n",
    "        sumy2 += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumx2*sumy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "train_texts_files = os.listdir(path+'base')\n",
    "target_texts_ids = [1, 2562, 1539, 3588, 3593, 2575, 939, 2066, 2579, 22, 3607, 536, 1561, 1054, 31, 2481, 1571, 3626, 2603, 45, 1076, 569, 570, 2656, 579, 3141, 1608, 586, 2635, 78, 1616, 1107, 3940, 2649, 2139, 2140, 607, 2144, 612, 1126, 1639, 2668, 2158, 3183, 636, 2174, 1151, 2688, 1666, 3203, 535, 3719, 3213, 3728, 2194, 147, 2708, 1174, 2712, 2201, 1691, 1180, 2206, 1697, 3748, 1701, 680, 2224, 1714, 3913, 695, 3256, 1726, 3775, 1728, 1217, 3780, 2758, 3783, 715, 2253, 110, 2258, 723, 1244, 1757, 2427, 3808, 2583, 1262, 240, 241, 60, 3827, 3830, 3456, 770, 3332, 262, 775, 776, 3850, 269, 273, 274, 2324, 789, 3547, 2337, 290, 2339, 1331, 2863, 2782, 3378, 307, 52, 2361, 2362, 3387, 3901, 833, 2884, 3397, 2374, 1154, 2891, 2896, 3409, 1849, 1367, 857, 3418, 347, 656, 1885, 2398, 1892, 2921, 829, 880, 1394, 2931, 2423, 888, 891, 382, 1920, 2028, 1928, 909, 3473, 2450, 1432, 581, 1437, 1951, 2977, 2467, 932, 2984, 413, 1963, 2992, 1457, 2377, 950, 1525, 3516, 1469, 587, 3007, 2806, 3545, 2510, 967, 3576, 462, 2126, 2003, 2006, 3544, 1227, 2010, 153, 2526, 2531, 375, 999, 2025, 2538, 3240, 2548, 1013, 887, 1016, 3065, 1020, 510, 511]\n",
    "target_texts_files = [x for x in os.listdir(path+'test') if int(x.replace(\"test_\", \"\").replace(\".txt\",  \"\")) in target_texts_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "target_texts = []\n",
    "for file in train_texts_files:\n",
    "    with open(path+'base/'+file, 'r') as f:\n",
    "        train_texts.append( strip_tags(f.read().lower()) )\n",
    "for file in target_texts_files:\n",
    "    with open(path+'test/'+file, 'r') as f:\n",
    "        target_texts.append( strip_tags(f.read().lower()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ищем прекрасного программиста 1с в дружный отдел сотрудников сферы it с неутомительным режимом работы. у нас есть 1с 8.2, 8.3, бухгалтерия строительной организации, жкх, зуп + самописные. что надо делать: - доработать существующие конфигурации,- разработать новые конфигураций,- отчеты, базы данных...- осуществлять поддержку наших продвинутых пользователей режим работы с 10 до 18 по вторникам и пятницам (строго!).  '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'продавецтребования:   пунктуальность, порядочность,  условия:   6 дневная рабочая неделя с 9.00- 19.00  обязанности:  продавец в контейнер 1000 мелочей (болты, гайки, инструменты, электроинструменты, саморезы и т.д. )   '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_texts)\n",
    "X_target_counts = count_vect.transform(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfTransformer(norm=None, smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_counts)\n",
    "X_target_tfidf = tf_idf.transform(X_target_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1461)\n",
      "(200, 1461)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts.shape)\n",
    "print(X_target_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.085336510249571187"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_vect_cosine_similarity(X_train_tfidf.toarray()[0], X_train_tfidf.toarray()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.08533651,  0.00973161,  0.03904741,  0.03681657,\n",
       "         0.35014289,  0.03681657,  0.06902423,  0.014982  ,  0.03681657,\n",
       "         0.01540582,  0.06119115,  0.01075213,  0.07372137,  0.03591924,\n",
       "         0.05083279,  0.06012874,  0.03876726,  0.03904741,  0.03531867]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X_train_tfidf[0:1], X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine similarity sum between train texts and each of the test texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_coisine_vect = []\n",
    "for text in range(len(target_texts)):\n",
    "    cs_vect = cosine_similarity(X_target_tfidf[text], X_train_tfidf)[0]  # 0 element bc we compared only 1 text\n",
    "    target_coisine_vect.append(sum(cs_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_cosine_mmean = np.mean(target_coisine_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [1 if x >= target_cosine_mmean else 0 for x in target_coisine_vect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "97\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "defined  = np.multiply([int(x.replace(\"test_\",\"\").replace(\".txt\",\"\").strip()) for x in target_texts_files], classes)\n",
    "print(len(defined))\n",
    "defined  = [np.asscalar(x) for x in defined if x > 0]  # To fix JSON Dump Erros we convert np.int64 to Python native int\n",
    "print(len(defined))\n",
    "other = [int(x.replace(\"test_\",\"\").replace(\".txt\",\"\").strip()) for x in target_texts_files if int(x.replace(\"test_\",\"\").replace(\".txt\",\"\")) not in defined]\n",
    "print(len(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(defined[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out =  {}\n",
    "out['defined'] = defined\n",
    "out['other'] = other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "out = json.dumps(out, ensure_ascii=False, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('lab4.json', 'w') as f:\n",
    "    f.write(str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
